{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e169c13-48e8-419f-861e-8c3bd36ba907",
   "metadata": {},
   "source": [
    "## CPSC 477 Final Project Part 3: Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ec6a8f3-e70e-4171-a4e6-e5ce8b2e9bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import evaluate\n",
    "from util import *\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "env = load_dotenv(override = True)\n",
    "rouge = evaluate.load(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba2ca684-0be1-4218-949f-ab94ee4775a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 50\n"
     ]
    }
   ],
   "source": [
    "# Obtained base model inference on test dataset \n",
    "# Took 20 min on V100 (Google Colab)\n",
    "\n",
    "test_filenames = os.listdir(\"base_model_inference\")\n",
    "if \".ipynb_checkpoints\" in test_filenames:\n",
    "    test_filenames.remove(\".ipynb_checkpoints\")\n",
    "\n",
    "candidates = []\n",
    "references = []\n",
    "ects = []\n",
    "for filename in test_filenames:\n",
    "    base_inference = \"\"\n",
    "    gemini_summary = \"\"\n",
    "    ect = \"\"\n",
    "    with open(f\"base_model_inference/{filename}\") as f:\n",
    "        base_inference = f.read()\n",
    "    with open(f\"dataset/test/gemini_summaries/{filename}\") as f:\n",
    "        gemini_summary = f.read()\n",
    "    with open(f\"dataset/test/ects/{filename}\") as f:\n",
    "        ect = f.read()\n",
    "    candidates.append(base_inference)\n",
    "    references.append(gemini_summary)\n",
    "    ects.append(ect)\n",
    "\n",
    "print(len(candidates), len(references))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01cc3059-5388-4f8c-ae13-9d544c4d1e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.43458448712829145, 'rouge2': 0.18709011156733035, 'rougeL': 0.26458870738914053, 'rougeLsum': 0.26826664661203936}\n"
     ]
    }
   ],
   "source": [
    "results = rouge.compute(predictions=candidates, references=references)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a39a3c6-02d5-4112-8d1c-f173b288c238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary numbers - precision and recall\n",
    "\n",
    "\n",
    "# Transcript numbers - precision and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f13738b7-d6ff-44ae-82e0-32c7bfc68946",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'OpenAI' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Generate summaries with GPT-3.5\u001b[39;00m\n\u001b[1;32m      2\u001b[0m client \u001b[38;5;241m=\u001b[39m OpenAI(api_key\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m())\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'OpenAI' object has no attribute 'keys'"
     ]
    }
   ],
   "source": [
    "# Generate summaries with GPT-3.5\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "prompt = \"Take this scraped input for a clothing item and list the following in the following format. For fields that you do not find, write N/A.\\nFormat:\\nMaterial: [X]% [Cotton or Organic Cotton or Polyester or Lyocell or Elastane or Polyamide or Elastomultiester], [X]% [Cotton or Organic Cotton or Polyester or Lyocell or Elastane or Polyamide or Elastomultiester or Other]…\\nRecycled Material: [X]%\\nCountry of Origin: [United States or Laos or Vietnam…]\\nCompany: [SHEIN or Amazon or GAP…]\\nClothing Item: [string]\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model = \"gpt-3.5-turbo\",\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a financial advisor tasked with creating a short summary of an earnings call transcript. You only want to summarize or re-iterate points that would be relevant, critical, or informational to someone who wants to skim over the important details of a long transcript.\"},\n",
    "        {\"role\": \"user\", \"Below is an earnings call transcript. Please summarize this transcript in exactly one paragraph using complete sentences. Keep the summary below 300 words. It is very important that you do not use any titles in the summary. Include relevant information and statistics from the Earnings Call Transcript in your summary.\\n\\nEarnings Call Transcript:\\n{}\"},\n",
    "    ]\n",
    ")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
