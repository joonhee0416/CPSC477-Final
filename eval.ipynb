{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e169c13-48e8-419f-861e-8c3bd36ba907",
   "metadata": {},
   "source": [
    "## CPSC 477 Final Project Part 3: Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ec6a8f3-e70e-4171-a4e6-e5ce8b2e9bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import evaluate\n",
    "from util import *\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "def extract_statistic(s, ignore_single_digit = False):\n",
    "    # The string should not be empty\n",
    "    s = s.replace(\",\", \"\") # Remove commas\n",
    "    if len(s) == 0:\n",
    "        return None\n",
    "    # It could be a valid number that is not a recent year (i.e 2015-2025)\n",
    "    if ignore_single_digit and is_float(s) and float(s) < 10:\n",
    "        return None\n",
    "    if is_float(s) and (float(s) < 2015 or float(s) > 2025):\n",
    "        return (float(s), None)\n",
    "    # In the form of $[valid number]\n",
    "    if s[0] == \"$\" and is_float(s[1:]):\n",
    "        return (float(s[1:]), \"$\")\n",
    "    # Or in the form of [valid number]%\n",
    "    if s[-1] == \"%\" and is_float(s[:-1]):\n",
    "        return (float(s[:-1]), \"%\")\n",
    "    return None\n",
    "\n",
    "def extract_numbers(text, ignore_single_digit = False):\n",
    "    words = [s for line in text.split(\"\\n\") for s in line.split(\" \")]\n",
    "    words = list(filter(len, words))\n",
    "    words = list(map(lambda s: s[:-1] if s[-1] in [\".\"] else s, words))\n",
    "    numbers = set(map(lambda w: extract_statistic(w, ignore_single_digit), words))\n",
    "    numbers.remove(None)\n",
    "    return list(numbers)\n",
    "\n",
    "def extract_key_points(ect, summary, ignore_single_digit = False):\n",
    "    ect_numbers = []\n",
    "    if len(ect) > max_ect_length:\n",
    "        front = ect[:max_ect_length // 2]\n",
    "        back = ect[-max_ect_length // 2:]\n",
    "        ect_numbers = extract_numbers(f\"{front}\\n{back}\", ignore_single_digit)\n",
    "    else:\n",
    "        ect_numbers = extract_numbers(ect, ignore_single_digit)\n",
    "    key_points = \"\"\n",
    "    key_points_numbers = []\n",
    "    for line in summary.split(\"\\n\"):\n",
    "        line_numbers = extract_numbers(line, ignore_single_digit)\n",
    "        ect_precision = 0\n",
    "        for n in line_numbers:\n",
    "            if n in ect_numbers:\n",
    "                ect_precision += 1\n",
    "        # print(len(ect), ect_precision, len(line_numbers))\n",
    "        if ect_precision > 0 and ect_precision == len(line_numbers):\n",
    "            key_points += line + \"\\n\"\n",
    "            key_points_numbers.extend(line_numbers)\n",
    "    return (key_points, list(set(key_points_numbers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba2ca684-0be1-4218-949f-ab94ee4775a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 50\n",
      "1180.48\n",
      "934.38\n"
     ]
    }
   ],
   "source": [
    "# Obtained base model inference on test dataset \n",
    "model = \"base_mistral_final\"\n",
    "\n",
    "test_filenames = os.listdir(f\"inference/{model}\")\n",
    "if \".ipynb_checkpoints\" in test_filenames:\n",
    "    test_filenames.remove(\".ipynb_checkpoints\")\n",
    "\n",
    "candidates = []\n",
    "references = []\n",
    "ects = []\n",
    "for filename in test_filenames:\n",
    "    base_inference = \"\"\n",
    "    gemini_summary = \"\"\n",
    "    ect = \"\"\n",
    "    with open(f\"inference/{model}/{filename}\") as f:\n",
    "        base_inference = f.read()\n",
    "    with open(f\"dataset/test/gemini_summaries/{filename}\") as f:\n",
    "        gemini_summary = f.read()\n",
    "    with open(f\"dataset/test/ects/{filename}\") as f:\n",
    "        ect = f.read()\n",
    "    candidates.append(base_inference)\n",
    "    references.append(gemini_summary)\n",
    "    ects.append(ect)\n",
    "\n",
    "print(len(candidates), len(references))\n",
    "\n",
    "candidate_lengths = list(map(len, candidates))\n",
    "print(sum(candidate_lengths) / len(candidate_lengths))\n",
    "\n",
    "reference_lengths = list(map(len, references))\n",
    "print(sum(reference_lengths) / len(reference_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "01cc3059-5388-4f8c-ae13-9d544c4d1e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline: {'rouge1': 0.44835118142896613, 'rouge2': 0.17846536649122435, 'rougeL': 0.26059977608446355, 'rougeLsum': 0.28815962106935133}\n"
     ]
    }
   ],
   "source": [
    "results = rouge.compute(predictions=candidates, references=references)\n",
    "print(f\"baseline: {results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a03700c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 50\n",
      "1167.94\n",
      "934.38\n"
     ]
    }
   ],
   "source": [
    "# Obtained base model inference on test dataset \n",
    "# Took 20 min on V100 (Google Colab)\n",
    "\n",
    "model = \"finetuned_mistral_final\"\n",
    "\n",
    "test_filenames = os.listdir(f\"inference/{model}\")\n",
    "if \".ipynb_checkpoints\" in test_filenames:\n",
    "    test_filenames.remove(\".ipynb_checkpoints\")\n",
    "\n",
    "candidates = []\n",
    "references = []\n",
    "ects = []\n",
    "for filename in test_filenames:\n",
    "    base_inference = \"\"\n",
    "    gemini_summary = \"\"\n",
    "    ect = \"\"\n",
    "    with open(f\"inference/{model}/{filename}\") as f:\n",
    "        base_inference = f.read()\n",
    "    with open(f\"dataset/test/gemini_summaries/{filename}\") as f:\n",
    "        gemini_summary = f.read()\n",
    "    with open(f\"dataset/test/ects/{filename}\") as f:\n",
    "        ect = f.read()\n",
    "    candidates.append(base_inference)\n",
    "    references.append(gemini_summary)\n",
    "    ects.append(ect)\n",
    "\n",
    "print(len(candidates), len(references))\n",
    "\n",
    "candidate_lengths = list(map(len, candidates))\n",
    "print(sum(candidate_lengths) / len(candidate_lengths))\n",
    "\n",
    "reference_lengths = list(map(len, references))\n",
    "print(sum(reference_lengths) / len(reference_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4a89c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fine-tuned: {'rouge1': 0.462058842316896, 'rouge2': 0.19530156234345203, 'rougeL': 0.2730591893592447, 'rougeLsum': 0.29365523442752167}\n"
     ]
    }
   ],
   "source": [
    "results = rouge.compute(predictions=candidates, references=references)\n",
    "print(f\"fine-tuned: {results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a39a3c6-02d5-4112-8d1c-f173b288c238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_1\n",
      "Gemini recall: [162, 380] 0.4263157894736842\n",
      "ECT recall [387, 1958] 0.1976506639427988\n",
      "Precision: [387, 394] 0.9822335025380711\n"
     ]
    }
   ],
   "source": [
    "gemini_recall = [0, 0]\n",
    "ect_recall = [0, 0]\n",
    "precision = [0, 0]\n",
    "transcript_recall = [0, 0]\n",
    "for i, filename in enumerate(test_filenames):\n",
    "    ect_numbers = extract_numbers(ects[i], True)\n",
    "    candidate_numbers = extract_numbers(candidates[i], True)\n",
    "    reference_numbers = extract_numbers(references[i],  True)\n",
    "    _, ectsum_numbers = extract_key_points(ects[i], references[i], True)\n",
    "    # Recall\n",
    "    recall = 0\n",
    "    for r in reference_numbers:\n",
    "        if r in candidate_numbers:\n",
    "            recall += 1\n",
    "    gemini_recall[0] += recall\n",
    "    gemini_recall[1] += len(reference_numbers)\n",
    "\n",
    "    recall = 0\n",
    "    for r in ect_numbers:\n",
    "        if r in candidate_numbers:\n",
    "            recall += 1\n",
    "    ect_recall[0] += recall\n",
    "    ect_recall[1] += len(ect_numbers)\n",
    " \n",
    "    # Precision\n",
    "    _precision = 0\n",
    "    for c in candidate_numbers:\n",
    "        if c in ect_numbers:\n",
    "            _precision += 1\n",
    "    precision[0] += _precision\n",
    "    precision[1] += len(candidate_numbers)\n",
    "\n",
    "print(model)\n",
    "print(\"Gemini recall:\", gemini_recall, gemini_recall[0] / gemini_recall[1])\n",
    "print(\"ECT recall\", ect_recall, ect_recall[0] / ect_recall[1])\n",
    "print(\"Precision:\", precision, precision[0] / precision[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13738b7-d6ff-44ae-82e0-32c7bfc68946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summaries with GPT-3.5\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "prompt = \"Take this scraped input for a clothing item and list the following in the following format. For fields that you do not find, write N/A.\\nFormat:\\nMaterial: [X]% [Cotton or Organic Cotton or Polyester or Lyocell or Elastane or Polyamide or Elastomultiester], [X]% [Cotton or Organic Cotton or Polyester or Lyocell or Elastane or Polyamide or Elastomultiester or Other]â€¦\\nRecycled Material: [X]%\\nCountry of Origin: [United States or Laos or Vietnamâ€¦]\\nCompany: [SHEIN or Amazon or GAPâ€¦]\\nClothing Item: [string]\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model = \"gpt-3.5-turbo\",\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a financial advisor tasked with creating a short summary of an earnings call transcript. You only want to summarize or re-iterate points that would be relevant, critical, or informational to someone who wants to skim over the important details of a long transcript.\"},\n",
    "        {\"role\": \"user\", \"Below is an earnings call transcript. Please summarize this transcript in exactly one paragraph using complete sentences. Keep the summary below 300 words. It is very important that you do not use any titles in the summary. Include relevant information and statistics from the Earnings Call Transcript in your summary.\\n\\nEarnings Call Transcript:\\n{}\"},\n",
    "    ]\n",
    ")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
